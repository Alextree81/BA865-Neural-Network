{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8YOCpyn-rKa"
      },
      "source": [
        "#**HOMEWORK: BLUE BIKE TRIP DURATION PREDICTION (Total: / 15 points)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxAF2jbRA3WY"
      },
      "source": [
        "Context: You have received some data from Blue Bikes (the Boston Bikesharing Service). They have asked you to provide a predictive model that can accurately predict how long a given bike rental will last, at the time the rental begins. The use case is that the bike share company wants to be able to predict how long a customer will have the bike in their possession, when they begin their retnal, in order to better manage operational efficiency across the bike network. Note that when the customer initiates a bike rental, they enter the starting station ID and ending station ID for their trip, into the mobile app."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMblm7NpWSY9"
      },
      "source": [
        "# *Name: Shu Wang*\n",
        "# *Email: swang99@bu.edu*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jF365-n0EC-q"
      },
      "source": [
        "#**Import and Pre-process Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import Data** "
      ],
      "metadata": {
        "id": "HG2lyAEI5Eoi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnmXkHjZ2VeB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "bluebikes = pd.read_csv('https://raw.githubusercontent.com/gburtch/BA865-2023/main/Lecture%20Materials/C_Assignment/bluebikes_sample.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x8mEld76g4S"
      },
      "source": [
        "There are several columns(start station name,end station name,user_type)that are non-numerical features.We need to examine these features first.It is reasonable to extract distance travelled based on the start/end longitude and latitude. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXx9Ytyl9p6W",
        "outputId": "8c769401-5d03-47d4-dd69-b53a649a664e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Subscriber' 'Customer']\n",
            "[1 2 0]\n"
          ]
        }
      ],
      "source": [
        "print(bluebikes.usertype.unique())\n",
        "print(bluebikes.gender.unique())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kpac1iFm9zHj"
      },
      "source": [
        "From the description of usertype and gender,they are categorical variables.I will transform these two variables to binary variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qk2RPo-6-k4h",
        "outputId": "2a42083a-c67a-4b93-e9dc-5dcad7abc5c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.6.0-py2.py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.2/81.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (0.5.3)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.5.3)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (0.13.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.10.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2022.7.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.2.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.9.0->category_encoders) (23.1)\n",
            "Installing collected packages: category_encoders\n",
            "Successfully installed category_encoders-2.6.0\n"
          ]
        }
      ],
      "source": [
        "pip install category_encoders\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TY1xVYSv_nxX"
      },
      "source": [
        "I will import the haversine package for distance calculation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyzPB84vnMXI",
        "outputId": "1075f794-05f5-4a73-e74e-0946d80aa0e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting haversine\n",
            "  Downloading haversine-2.8.0-py2.py3-none-any.whl (7.7 kB)\n",
            "Installing collected packages: haversine\n",
            "Successfully installed haversine-2.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install haversine"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import haversine as hs\n",
        "from haversine import Unit"
      ],
      "metadata": {
        "id": "3AzDQrR_wZWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Preprocess Data** "
      ],
      "metadata": {
        "id": "jnZfvC9X61Ps"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Analysis on feature selection**"
      ],
      "metadata": {
        "id": "SmFFg3ZRSuNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bluebikes.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "id": "r718GBOMvDE3",
        "outputId": "07d20373-69c5-41b4-a165-c7c29d12ce3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   tripduration starttime stoptime  start station id  \\\n",
              "0          1584   09:36.7  36:00.9               442   \n",
              "1           894   40:48.2  55:43.0                80   \n",
              "2           973   58:05.4  14:18.4                57   \n",
              "3           606   46:45.0  56:51.4               149   \n",
              "4           428   49:27.9  56:36.7               426   \n",
              "\n",
              "                        start station name  start station latitude  \\\n",
              "0            Hyde Park Ave at Walk Hill St               42.296067   \n",
              "1  MIT Stata Center at Vassar St / Main St               42.362131   \n",
              "2        Columbus Ave at Massachusetts Ave               42.340543   \n",
              "3                         175 N Harvard St               42.363796   \n",
              "4                  Surface Rd at Summer St               42.352946   \n",
              "\n",
              "   start station longitude  end station id  \\\n",
              "0               -71.116012             122   \n",
              "1               -71.091156             144   \n",
              "2               -71.081388              68   \n",
              "3               -71.129164             221   \n",
              "4               -71.056564             420   \n",
              "\n",
              "                        end station name  end station latitude  \\\n",
              "0        Burlington Ave at Brookline Ave             42.345733   \n",
              "1                  Rogers St & Land Blvd             42.365758   \n",
              "2  Central Square at Mass Ave / Essex St             42.365070   \n",
              "3  Verizon Innovation Hub 10 Ware Street             42.372509   \n",
              "4              Charles St at Pinckney St             42.358725   \n",
              "\n",
              "   end station longitude  bikeid    usertype  birth year  gender  \n",
              "0             -71.100694    4587  Subscriber        1967       1  \n",
              "1             -71.076994    2340  Subscriber        1994       1  \n",
              "2             -71.103100    2910  Subscriber        1994       1  \n",
              "3             -71.113054    4526  Subscriber        1992       1  \n",
              "4             -71.070795    3780  Subscriber        1989       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-469bc836-bbee-40db-8750-feab6386bc2e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tripduration</th>\n",
              "      <th>starttime</th>\n",
              "      <th>stoptime</th>\n",
              "      <th>start station id</th>\n",
              "      <th>start station name</th>\n",
              "      <th>start station latitude</th>\n",
              "      <th>start station longitude</th>\n",
              "      <th>end station id</th>\n",
              "      <th>end station name</th>\n",
              "      <th>end station latitude</th>\n",
              "      <th>end station longitude</th>\n",
              "      <th>bikeid</th>\n",
              "      <th>usertype</th>\n",
              "      <th>birth year</th>\n",
              "      <th>gender</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1584</td>\n",
              "      <td>09:36.7</td>\n",
              "      <td>36:00.9</td>\n",
              "      <td>442</td>\n",
              "      <td>Hyde Park Ave at Walk Hill St</td>\n",
              "      <td>42.296067</td>\n",
              "      <td>-71.116012</td>\n",
              "      <td>122</td>\n",
              "      <td>Burlington Ave at Brookline Ave</td>\n",
              "      <td>42.345733</td>\n",
              "      <td>-71.100694</td>\n",
              "      <td>4587</td>\n",
              "      <td>Subscriber</td>\n",
              "      <td>1967</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>894</td>\n",
              "      <td>40:48.2</td>\n",
              "      <td>55:43.0</td>\n",
              "      <td>80</td>\n",
              "      <td>MIT Stata Center at Vassar St / Main St</td>\n",
              "      <td>42.362131</td>\n",
              "      <td>-71.091156</td>\n",
              "      <td>144</td>\n",
              "      <td>Rogers St &amp; Land Blvd</td>\n",
              "      <td>42.365758</td>\n",
              "      <td>-71.076994</td>\n",
              "      <td>2340</td>\n",
              "      <td>Subscriber</td>\n",
              "      <td>1994</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>973</td>\n",
              "      <td>58:05.4</td>\n",
              "      <td>14:18.4</td>\n",
              "      <td>57</td>\n",
              "      <td>Columbus Ave at Massachusetts Ave</td>\n",
              "      <td>42.340543</td>\n",
              "      <td>-71.081388</td>\n",
              "      <td>68</td>\n",
              "      <td>Central Square at Mass Ave / Essex St</td>\n",
              "      <td>42.365070</td>\n",
              "      <td>-71.103100</td>\n",
              "      <td>2910</td>\n",
              "      <td>Subscriber</td>\n",
              "      <td>1994</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>606</td>\n",
              "      <td>46:45.0</td>\n",
              "      <td>56:51.4</td>\n",
              "      <td>149</td>\n",
              "      <td>175 N Harvard St</td>\n",
              "      <td>42.363796</td>\n",
              "      <td>-71.129164</td>\n",
              "      <td>221</td>\n",
              "      <td>Verizon Innovation Hub 10 Ware Street</td>\n",
              "      <td>42.372509</td>\n",
              "      <td>-71.113054</td>\n",
              "      <td>4526</td>\n",
              "      <td>Subscriber</td>\n",
              "      <td>1992</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>428</td>\n",
              "      <td>49:27.9</td>\n",
              "      <td>56:36.7</td>\n",
              "      <td>426</td>\n",
              "      <td>Surface Rd at Summer St</td>\n",
              "      <td>42.352946</td>\n",
              "      <td>-71.056564</td>\n",
              "      <td>420</td>\n",
              "      <td>Charles St at Pinckney St</td>\n",
              "      <td>42.358725</td>\n",
              "      <td>-71.070795</td>\n",
              "      <td>3780</td>\n",
              "      <td>Subscriber</td>\n",
              "      <td>1989</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-469bc836-bbee-40db-8750-feab6386bc2e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-469bc836-bbee-40db-8750-feab6386bc2e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-469bc836-bbee-40db-8750-feab6386bc2e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check 1-1 correspondence of station id and station name\n",
        "print(bluebikes.groupby('start station id')[\"start station name\"].nunique().max()==1)\n",
        "print(bluebikes.groupby('end station id')[\"end station name\"].nunique().max()==1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y84yE9tVl9GX",
        "outputId": "4730597e-932f-4188-8e45-0cedf5fc7017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see from above,Station Name has 1-1 correspondence with Station id.the station id,station name variables doesn't add useful information to the model,so we will drop these variables.The start time and end time only records the minute/second/microsecond,with no information on hour.I will transform the start time/end time to seconds within an hour(e.g, 9:36.7 will be transformed into 576.7 seconds)."
      ],
      "metadata": {
        "id": "LchZpbGbSch5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Nx78_rA_vNt"
      },
      "outputs": [],
      "source": [
        "# This function MUST return a pair of objects (predictors, labels, in that order) as numpy arrays.\n",
        "import category_encoders as ce\n",
        "def processData(data):\n",
        "    \n",
        "  ce_OHE = ce.OneHotEncoder(cols=['usertype','gender'])\n",
        "  #transform the user_type variable to onehot-encoder.\n",
        "  data = ce_OHE.fit_transform(data)  \n",
        "  #create two new columns representing the start time and end time within an hour\n",
        "  data[\"starttime_inhour\"] = ''\n",
        "  data[\"endtime_inhour\"] = ''\n",
        "  #create a column calculating distance\n",
        "  data[\"distance\"] = ''\n",
        "  len = data.shape[0]\n",
        "  for i in range(0,len):\n",
        "   data[\"starttime_inhour\"][i] = int(data[\"starttime\"][i][0:2])*60 + int(data[\"starttime\"][i][3:5]) + float(data[\"starttime\"][i][5:7])\n",
        "   data[\"endtime_inhour\"][i] = int(data[\"stoptime\"][i][0:2])*60 + int(data[\"stoptime\"][i][3:5]) + float(data[\"stoptime\"][i][5:7])\n",
        "   data[\"distance\"][i] = hs.haversine((data[\"start station latitude\"][i],data[\"start station longitude\"][i]),(data[\"end station latitude\"][i],data[\"end station longitude\"][i]))\n",
        "  #drop the original two object columns\n",
        "  data = data.drop(columns = [\"starttime\",\"stoptime\"])\n",
        "  #drop other variables that will not be used in the neural network\n",
        "  data = data.drop(columns = [\"start station name\",\"end station name\",\"start station latitude\",\"end station latitude\",\"start station longitude\",\"end station longitude\",\"start station id\",\"end station id\",\"bikeid\"])\n",
        "  #transform the dataframe into arrays\n",
        "  arrays = data.values\n",
        "  train_predictors = arrays[:,1:10]\n",
        "  train_labels = arrays[:,0]\n",
        "  #transform the arrays to float type\n",
        "  train_predictors = np.asarray(train_predictors).astype(np.float32)\n",
        "  train_labels = np.asarray(train_labels).astype(np.float32)\n",
        "  return train_predictors, train_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhnwnEtEOeXd"
      },
      "source": [
        "#**Building Neural Network Architecture and Processing Sample**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KZXFE1fWMcj"
      },
      "source": [
        "Calling the data pre-processing function on the sample."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HToKOpiSoZmf",
        "outputId": "983329bc-d221-4eb9-a22c-0cc5bd3045cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-8b4ede47dd52>:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[\"starttime_inhour\"][i] = int(data[\"starttime\"][i][0:2])*60 + int(data[\"starttime\"][i][3:5]) + float(data[\"starttime\"][i][5:7])\n",
            "<ipython-input-12-8b4ede47dd52>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[\"endtime_inhour\"][i] = int(data[\"stoptime\"][i][0:2])*60 + int(data[\"stoptime\"][i][3:5]) + float(data[\"stoptime\"][i][5:7])\n",
            "<ipython-input-12-8b4ede47dd52>:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[\"distance\"][i] = hs.haversine((data[\"start station latitude\"][i],data[\"start station longitude\"][i]),(data[\"end station latitude\"][i],data[\"end station longitude\"][i]))\n"
          ]
        }
      ],
      "source": [
        "predictors, labels = processData(bluebikes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ8j9CzTmcVC",
        "outputId": "e198a8bb-af73-458c-f811-4ccff32929d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.000000e+00, 0.000000e+00, 1.967000e+03, 1.000000e+00,\n",
              "       0.000000e+00, 0.000000e+00, 5.767000e+02, 2.160900e+03,\n",
              "       5.664386e+00], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "#preview the predictor variable\n",
        "predictors[0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGYaiNdpoako"
      },
      "source": [
        "Specifying my Neural Network's structure. Note that the important thing for performance with this model actually comes down to its depth! It turns out that width isn't that important here. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Build Neural Network Model** "
      ],
      "metadata": {
        "id": "QsNN0X9L7J4U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6FG-8pICdht"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import BatchNormalization\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "    \n",
        "    model = keras.Sequential(name=\"Bluebikes-Duration-Model\")\n",
        "\n",
        "    \n",
        "    model.add(tf.keras.layers.Dense(256, input_shape=(predictors.shape[1],)))\n",
        "    #add drop out rate\n",
        "    model.add(Dropout(0.3))\n",
        "    \n",
        "\n",
        "    model.add(layers.Dense(128, activation=\"relu\",name=\"first_hidden\"))\n",
        "    model.add(Dropout(0.3))\n",
        "    #add normalization\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(layers.Dense(64, activation=\"relu\",name=\"second_hidden\"))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(layers.Dense(32, activation=\"relu\",name=\"third_hidden\"))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(layers.Dense(16, activation=\"relu\",name=\"fourth_hidden\"))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "    model.add(layers.Dense(1,name=\"output\"))\n",
        "\n",
        "    \n",
        "    optimizer = keras.optimizers.RMSprop(learning_rate=1e-3)\n",
        "    \n",
        "# Compile the model.\n",
        "    model.compile(optimizer= optimizer, loss=\"mse\", metrics=[\"mae\"])  \n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "t246ZImPsBDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5etiTCpuMQH5"
      },
      "source": [
        "#**Training Neural Network**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Training on whole dataset**"
      ],
      "metadata": {
        "id": "_JUfczW27ho0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We first train the model on whole dataset, then use cross-validation."
      ],
      "metadata": {
        "id": "zDOXAvlQdMB1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imfRiESllpKm",
        "outputId": "ed61c487-bf16-4d89-ee95-2820c1f74424"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "141/141 [==============================] - 9s 7ms/step - loss: 2677498.7500 - mae: 849.3536\n",
            "Epoch 2/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 2674157.0000 - mae: 848.0148\n",
            "Epoch 3/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 2668172.7500 - mae: 846.0653\n",
            "Epoch 4/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 2659760.0000 - mae: 843.4628\n",
            "Epoch 5/100\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 2650691.2500 - mae: 840.2506\n",
            "Epoch 6/100\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 2640594.7500 - mae: 836.4407\n",
            "Epoch 7/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 2629289.5000 - mae: 831.9937\n",
            "Epoch 8/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 2616034.0000 - mae: 826.9525\n",
            "Epoch 9/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 2603610.5000 - mae: 821.3140\n",
            "Epoch 10/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 2586403.7500 - mae: 815.0306\n",
            "Epoch 11/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 2570532.7500 - mae: 808.1523\n",
            "Epoch 12/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 2552936.0000 - mae: 800.6880\n",
            "Epoch 13/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 2534173.7500 - mae: 792.7230\n",
            "Epoch 14/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 2515615.5000 - mae: 784.0317\n",
            "Epoch 15/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 2495192.2500 - mae: 774.7216\n",
            "Epoch 16/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 2469611.0000 - mae: 765.1052\n",
            "Epoch 17/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 2449595.5000 - mae: 754.6023\n",
            "Epoch 18/100\n",
            "141/141 [==============================] - 2s 15ms/step - loss: 2424136.7500 - mae: 743.4622\n",
            "Epoch 19/100\n",
            "141/141 [==============================] - 1s 10ms/step - loss: 2402745.5000 - mae: 731.8605\n",
            "Epoch 20/100\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 2378226.5000 - mae: 719.6052\n",
            "Epoch 21/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 2350580.5000 - mae: 707.4438\n",
            "Epoch 22/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 2323194.7500 - mae: 693.7033\n",
            "Epoch 23/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 2296539.2500 - mae: 679.8585\n",
            "Epoch 24/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 2270284.0000 - mae: 665.6640\n",
            "Epoch 25/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 2243708.2500 - mae: 650.3961\n",
            "Epoch 26/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 2214500.5000 - mae: 634.6810\n",
            "Epoch 27/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 2186872.0000 - mae: 619.0294\n",
            "Epoch 28/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 2159203.0000 - mae: 602.2587\n",
            "Epoch 29/100\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 2133275.7500 - mae: 585.5789\n",
            "Epoch 30/100\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 2099440.0000 - mae: 568.1002\n",
            "Epoch 31/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 2075709.5000 - mae: 550.2075\n",
            "Epoch 32/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 2047744.5000 - mae: 533.4704\n",
            "Epoch 33/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 2015061.5000 - mae: 514.2234\n",
            "Epoch 34/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1994467.3750 - mae: 494.7768\n",
            "Epoch 35/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1963429.6250 - mae: 475.8974\n",
            "Epoch 36/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1938547.8750 - mae: 457.7885\n",
            "Epoch 37/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1917466.3750 - mae: 439.2118\n",
            "Epoch 38/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1892443.6250 - mae: 420.9416\n",
            "Epoch 39/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1861806.7500 - mae: 402.9865\n",
            "Epoch 40/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 1849407.7500 - mae: 384.6642\n",
            "Epoch 41/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1825034.2500 - mae: 367.3205\n",
            "Epoch 42/100\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 1801239.5000 - mae: 347.6199\n",
            "Epoch 43/100\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 1782071.1250 - mae: 332.3194\n",
            "Epoch 44/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 1770461.2500 - mae: 317.1665\n",
            "Epoch 45/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1753607.7500 - mae: 305.1390\n",
            "Epoch 46/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1756100.1250 - mae: 293.3262\n",
            "Epoch 47/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1725017.8750 - mae: 282.7971\n",
            "Epoch 48/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 1714515.0000 - mae: 277.0606\n",
            "Epoch 49/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1707406.6250 - mae: 271.0218\n",
            "Epoch 50/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 1695914.5000 - mae: 265.0846\n",
            "Epoch 51/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1700738.3750 - mae: 264.7072\n",
            "Epoch 52/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1690712.8750 - mae: 259.5686\n",
            "Epoch 53/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1676867.2500 - mae: 260.0306\n",
            "Epoch 54/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1683705.1250 - mae: 262.7788\n",
            "Epoch 55/100\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 1700094.7500 - mae: 267.9573\n",
            "Epoch 56/100\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 1689070.8750 - mae: 263.1616\n",
            "Epoch 57/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 1682401.0000 - mae: 269.7101\n",
            "Epoch 58/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1667005.7500 - mae: 266.1100\n",
            "Epoch 59/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1678584.1250 - mae: 269.1530\n",
            "Epoch 60/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1670697.8750 - mae: 269.9521\n",
            "Epoch 61/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 1661604.3750 - mae: 268.5189\n",
            "Epoch 62/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1687249.8750 - mae: 270.6771\n",
            "Epoch 63/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1673086.1250 - mae: 268.4146\n",
            "Epoch 64/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1671122.5000 - mae: 270.4250\n",
            "Epoch 65/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1685863.2500 - mae: 273.3610\n",
            "Epoch 66/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1658357.2500 - mae: 272.8546\n",
            "Epoch 67/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 1678706.3750 - mae: 271.7012\n",
            "Epoch 68/100\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 1673370.0000 - mae: 270.4075\n",
            "Epoch 69/100\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 1656882.1250 - mae: 270.8249\n",
            "Epoch 70/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 1681183.0000 - mae: 277.8304\n",
            "Epoch 71/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1673501.5000 - mae: 271.8461\n",
            "Epoch 72/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1680839.8750 - mae: 274.8946\n",
            "Epoch 73/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 1670597.8750 - mae: 275.9259\n",
            "Epoch 74/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1668343.7500 - mae: 276.0601\n",
            "Epoch 75/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 1667728.0000 - mae: 277.9589\n",
            "Epoch 76/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1674909.7500 - mae: 277.2202\n",
            "Epoch 77/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1684424.6250 - mae: 275.2753\n",
            "Epoch 78/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1667036.5000 - mae: 272.9735\n",
            "Epoch 79/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1673965.5000 - mae: 275.3539\n",
            "Epoch 80/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 1687765.8750 - mae: 280.8055\n",
            "Epoch 81/100\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 1681254.8750 - mae: 274.9393\n",
            "Epoch 82/100\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 1676138.0000 - mae: 273.0309\n",
            "Epoch 83/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 1669757.2500 - mae: 274.1659\n",
            "Epoch 84/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 1684456.2500 - mae: 274.3021\n",
            "Epoch 85/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 1663692.6250 - mae: 275.5703\n",
            "Epoch 86/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1671627.8750 - mae: 270.9171\n",
            "Epoch 87/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1678130.7500 - mae: 276.3614\n",
            "Epoch 88/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1678692.1250 - mae: 272.9398\n",
            "Epoch 89/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1677137.6250 - mae: 273.9901\n",
            "Epoch 90/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1678929.5000 - mae: 275.1657\n",
            "Epoch 91/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1658990.1250 - mae: 273.0497\n",
            "Epoch 92/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1666350.7500 - mae: 273.9732\n",
            "Epoch 93/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1662341.0000 - mae: 275.8801\n",
            "Epoch 94/100\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 1679504.0000 - mae: 275.1253\n",
            "Epoch 95/100\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 1670682.0000 - mae: 275.6275\n",
            "Epoch 96/100\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 1673537.7500 - mae: 277.1237\n",
            "Epoch 97/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1674208.2500 - mae: 272.8818\n",
            "Epoch 98/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1660433.7500 - mae: 270.9292\n",
            "Epoch 99/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1678157.5000 - mae: 275.0194\n",
            "Epoch 100/100\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1692489.6250 - mae: 270.6255\n"
          ]
        }
      ],
      "source": [
        "model = build_model()\n",
        "num_epochs = 100\n",
        "batch_size = 64\n",
        "all_mae_histories = [] \n",
        "#fit the model into whole dataset\n",
        "history = model.fit(predictors, labels,epochs=num_epochs, batch_size=batch_size, verbose=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFmTG4fwNBg0",
        "outputId": "1cefeb00-0f31-49d9-8d45-93bda608c5bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'mae'])\n"
          ]
        }
      ],
      "source": [
        "print(history.history.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epctFt76MwCP"
      },
      "outputs": [],
      "source": [
        "all_mae_histories = []\n",
        "mae_history = history.history['mae']\n",
        "all_mae_histories.append(mae_history)\n",
        "#calculate MAE on the whole dataset\n",
        "average_mae_history = [np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcD7R5-UG8sl"
      },
      "source": [
        "###**Model Performance over Training:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Build your plot.\n",
        "print(average_mae_history[-1])\n",
        "\n",
        "plt.plot(average_mae_history)\n",
        "plt.ylabel('Training MAE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Mean Absolute Error Over Training')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "YxdRiS9Fym_l",
        "outputId": "97b90cbc-1c96-4d33-e035-98dabee58e63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "272.9676818847656\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Cross Validation**"
      ],
      "metadata": {
        "id": "6vVGNXXi7s6Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Model Performance on Cross Validation**"
      ],
      "metadata": {
        "id": "8lmG92jRV5g9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = 4 \n",
        "num_val_samples = len(predictors) // k # floor division (i.e., round down to nearest integer.)\n",
        "num_epochs = 100\n",
        "all_val_mae_histories = []  \n",
        "all_train_histories=[]\n",
        "\n",
        "print(\"In total, we have\",len(predictors),\"training observations.\")\n",
        "print(\"With a k of\",k,\"we have\",num_val_samples,\"observations per fold.\\n\")\n",
        "\n",
        "for i in range(k): # the folds are going to be indexed 0 through 3 if k = 4\n",
        "    print(\"Processing fold #:\",i)\n",
        "    \n",
        "    # This is important here, because the last fold won't produce an error, despite our slice going well beyond the end of the array.\n",
        "    print(\"Validation data includes observations\",i*num_val_samples,\"through\",(i+1)*num_val_samples-1) # minus 1 because a slice is up to and not including the second index.\n",
        "    val_data = predictors[i * num_val_samples: (i + 1) * num_val_samples] \n",
        "    val_targets = labels[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    print(\"Training data includes observations 0 through\",i*num_val_samples-1,\"joined with observations\",(i+1)*num_val_samples,\"through the final observation.\\n\")\n",
        "    partial_train_data = np.concatenate(\n",
        "        [predictors[:i * num_val_samples],\n",
        "         predictors[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "    partial_train_targets = np.concatenate(\n",
        "        [labels[:i * num_val_samples],\n",
        "         labels[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "    model = build_model()\n",
        "    history = model.fit(partial_train_data, partial_train_targets,\n",
        "                        validation_data=(val_data, val_targets),\n",
        "                        epochs=num_epochs, batch_size=64, verbose=1)\n",
        "    val_mae_history = history.history['val_mae']\n",
        "    \n",
        "    mae_history = history.history['mae']\n",
        "    all_val_mae_histories.append(val_mae_history)\n",
        "    all_train_histories.append(mae_history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aahqZ0A_sM5h",
        "outputId": "275e0df7-e656-4f0c-dc3c-82a3c01f2a18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In total, we have 9000 training observations.\n",
            "With a k of 4 we have 2250 observations per fold.\n",
            "\n",
            "Processing fold #: 0\n",
            "Validation data includes observations 0 through 2249\n",
            "Training data includes observations 0 through -1 joined with observations 2250 through the final observation.\n",
            "\n",
            "Epoch 1/100\n",
            "106/106 [==============================] - 8s 17ms/step - loss: 3031133.7500 - mae: 854.8290 - val_loss: 1617580.3750 - val_mae: 833.6208\n",
            "Epoch 2/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 3028658.2500 - mae: 853.9536 - val_loss: 1612869.3750 - val_mae: 832.8726\n",
            "Epoch 3/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 3024546.2500 - mae: 852.7313 - val_loss: 1614762.5000 - val_mae: 835.3184\n",
            "Epoch 4/100\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 3019504.2500 - mae: 851.1476 - val_loss: 1604683.8750 - val_mae: 832.0151\n",
            "Epoch 5/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 3013441.5000 - mae: 849.2255 - val_loss: 1590684.2500 - val_mae: 825.9957\n",
            "Epoch 6/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 3006512.0000 - mae: 846.9788 - val_loss: 1582363.5000 - val_mae: 822.0632\n",
            "Epoch 7/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2999738.2500 - mae: 844.3412 - val_loss: 1580601.6250 - val_mae: 822.2166\n",
            "Epoch 8/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2991585.5000 - mae: 841.3748 - val_loss: 1578729.1250 - val_mae: 822.4192\n",
            "Epoch 9/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2982648.0000 - mae: 838.0670 - val_loss: 1568375.6250 - val_mae: 817.8381\n",
            "Epoch 10/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2973136.0000 - mae: 834.4323 - val_loss: 1557385.5000 - val_mae: 813.7223\n",
            "Epoch 11/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2963292.2500 - mae: 830.4355 - val_loss: 1541948.6250 - val_mae: 807.6422\n",
            "Epoch 12/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 2951755.0000 - mae: 826.0918 - val_loss: 1533077.0000 - val_mae: 804.0362\n",
            "Epoch 13/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 2940280.7500 - mae: 821.4123 - val_loss: 1525154.1250 - val_mae: 800.5237\n",
            "Epoch 14/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 2926870.2500 - mae: 816.3997 - val_loss: 1519390.6250 - val_mae: 798.5033\n",
            "Epoch 15/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 2915785.0000 - mae: 811.1218 - val_loss: 1494302.0000 - val_mae: 788.8906\n",
            "Epoch 16/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 2902031.7500 - mae: 805.4221 - val_loss: 1486811.8750 - val_mae: 785.0494\n",
            "Epoch 17/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2885687.2500 - mae: 799.3625 - val_loss: 1478704.5000 - val_mae: 781.7708\n",
            "Epoch 18/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2871486.2500 - mae: 793.0953 - val_loss: 1452457.8750 - val_mae: 770.7593\n",
            "Epoch 19/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2856317.5000 - mae: 786.3654 - val_loss: 1438510.7500 - val_mae: 765.3967\n",
            "Epoch 20/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2838752.2500 - mae: 779.3008 - val_loss: 1436624.5000 - val_mae: 763.5132\n",
            "Epoch 21/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2821292.2500 - mae: 772.0076 - val_loss: 1419138.8750 - val_mae: 754.6653\n",
            "Epoch 22/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2807547.7500 - mae: 764.4745 - val_loss: 1381113.3750 - val_mae: 738.7720\n",
            "Epoch 23/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2789988.2500 - mae: 756.6808 - val_loss: 1344995.2500 - val_mae: 720.5477\n",
            "Epoch 24/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2772145.2500 - mae: 748.2208 - val_loss: 1371036.5000 - val_mae: 736.2888\n",
            "Epoch 25/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2750750.0000 - mae: 739.8835 - val_loss: 1317389.2500 - val_mae: 708.8550\n",
            "Epoch 26/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2735808.2500 - mae: 731.2501 - val_loss: 1321522.7500 - val_mae: 713.1160\n",
            "Epoch 27/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2709686.2500 - mae: 721.2573 - val_loss: 1289331.2500 - val_mae: 692.7850\n",
            "Epoch 28/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 2692610.0000 - mae: 711.3375 - val_loss: 1280315.2500 - val_mae: 692.5172\n",
            "Epoch 29/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 2672932.5000 - mae: 701.9891 - val_loss: 1255549.0000 - val_mae: 676.0594\n",
            "Epoch 30/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2658681.7500 - mae: 692.0055 - val_loss: 1254145.7500 - val_mae: 676.2309\n",
            "Epoch 31/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2629256.5000 - mae: 680.6722 - val_loss: 1182394.8750 - val_mae: 637.7775\n",
            "Epoch 32/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2611070.7500 - mae: 669.5001 - val_loss: 1155445.3750 - val_mae: 622.8647\n",
            "Epoch 33/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2587056.7500 - mae: 658.4821 - val_loss: 1174375.2500 - val_mae: 636.7285\n",
            "Epoch 34/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2574495.2500 - mae: 647.4156 - val_loss: 1128913.1250 - val_mae: 608.5917\n",
            "Epoch 35/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2551011.5000 - mae: 634.8330 - val_loss: 1150610.3750 - val_mae: 621.0357\n",
            "Epoch 36/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2523375.5000 - mae: 623.4812 - val_loss: 1116929.0000 - val_mae: 602.7267\n",
            "Epoch 37/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2508895.2500 - mae: 610.8035 - val_loss: 1096084.5000 - val_mae: 588.6957\n",
            "Epoch 38/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2477968.5000 - mae: 599.4708 - val_loss: 1083895.2500 - val_mae: 580.9435\n",
            "Epoch 39/100\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 2467180.0000 - mae: 585.5328 - val_loss: 1059440.1250 - val_mae: 564.0484\n",
            "Epoch 40/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2434230.5000 - mae: 572.5512 - val_loss: 1064928.3750 - val_mae: 566.4354\n",
            "Epoch 41/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2422746.5000 - mae: 561.6624 - val_loss: 1030312.9375 - val_mae: 544.0826\n",
            "Epoch 42/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 2399949.2500 - mae: 545.6771 - val_loss: 1013474.4375 - val_mae: 545.6418\n",
            "Epoch 43/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 2371224.5000 - mae: 531.6983 - val_loss: 1035827.4375 - val_mae: 553.5319\n",
            "Epoch 44/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2371566.5000 - mae: 517.8084 - val_loss: 949164.6875 - val_mae: 496.0438\n",
            "Epoch 45/100\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 2330390.0000 - mae: 504.0434 - val_loss: 949711.5625 - val_mae: 491.7636\n",
            "Epoch 46/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2319554.2500 - mae: 492.1097 - val_loss: 927162.8125 - val_mae: 476.0913\n",
            "Epoch 47/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2305156.0000 - mae: 476.8665 - val_loss: 875897.1875 - val_mae: 449.0273\n",
            "Epoch 48/100\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 2284262.5000 - mae: 463.4964 - val_loss: 863980.8125 - val_mae: 437.4992\n",
            "Epoch 49/100\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 2261278.0000 - mae: 447.3445 - val_loss: 847114.6250 - val_mae: 418.1115\n",
            "Epoch 50/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2241402.5000 - mae: 433.6219 - val_loss: 896060.1250 - val_mae: 467.4202\n",
            "Epoch 51/100\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 2236428.2500 - mae: 419.6848 - val_loss: 833525.3750 - val_mae: 409.3413\n",
            "Epoch 52/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2203322.2500 - mae: 408.4710 - val_loss: 802358.1875 - val_mae: 382.6375\n",
            "Epoch 53/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2186594.5000 - mae: 392.6501 - val_loss: 815787.7500 - val_mae: 400.2674\n",
            "Epoch 54/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2168456.5000 - mae: 379.6340 - val_loss: 768875.0625 - val_mae: 346.6935\n",
            "Epoch 55/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2155323.2500 - mae: 363.5768 - val_loss: 821917.0625 - val_mae: 394.7248\n",
            "Epoch 56/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 2140056.5000 - mae: 356.4980 - val_loss: 768913.0625 - val_mae: 353.2147\n",
            "Epoch 57/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 2111543.2500 - mae: 340.6460 - val_loss: 710731.1875 - val_mae: 291.5716\n",
            "Epoch 58/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2115582.7500 - mae: 328.4431 - val_loss: 735828.6250 - val_mae: 325.2917\n",
            "Epoch 59/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2111990.5000 - mae: 321.0392 - val_loss: 702848.3125 - val_mae: 290.9287\n",
            "Epoch 60/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2093992.1250 - mae: 308.0180 - val_loss: 653240.0000 - val_mae: 215.2691\n",
            "Epoch 61/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2077277.8750 - mae: 295.8838 - val_loss: 722655.4375 - val_mae: 299.6398\n",
            "Epoch 62/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2077300.2500 - mae: 293.7040 - val_loss: 664208.5625 - val_mae: 231.0026\n",
            "Epoch 63/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2053816.5000 - mae: 280.7466 - val_loss: 657708.1875 - val_mae: 239.6949\n",
            "Epoch 64/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2052091.2500 - mae: 278.5310 - val_loss: 658925.0000 - val_mae: 235.3308\n",
            "Epoch 65/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2031922.6250 - mae: 272.5971 - val_loss: 637580.1875 - val_mae: 202.0196\n",
            "Epoch 66/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2043916.7500 - mae: 266.7689 - val_loss: 668304.5000 - val_mae: 233.7706\n",
            "Epoch 67/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2035982.1250 - mae: 267.1781 - val_loss: 663521.8750 - val_mae: 257.4059\n",
            "Epoch 68/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2035047.7500 - mae: 263.2398 - val_loss: 659456.3125 - val_mae: 246.4836\n",
            "Epoch 69/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 2029952.7500 - mae: 267.2336 - val_loss: 618836.1875 - val_mae: 184.1059\n",
            "Epoch 70/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 2025969.6250 - mae: 262.3798 - val_loss: 613152.3750 - val_mae: 176.4968\n",
            "Epoch 71/100\n",
            "106/106 [==============================] - 1s 14ms/step - loss: 2013136.5000 - mae: 260.0872 - val_loss: 618670.7500 - val_mae: 183.0375\n",
            "Epoch 72/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 2007284.3750 - mae: 262.4239 - val_loss: 625091.6875 - val_mae: 184.9888\n",
            "Epoch 73/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 2004026.7500 - mae: 257.4116 - val_loss: 644136.8750 - val_mae: 204.2666\n",
            "Epoch 74/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2035241.7500 - mae: 260.7835 - val_loss: 600850.6875 - val_mae: 150.2973\n",
            "Epoch 75/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2006080.6250 - mae: 257.9575 - val_loss: 600252.7500 - val_mae: 152.7641\n",
            "Epoch 76/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2012608.6250 - mae: 261.8925 - val_loss: 624134.7500 - val_mae: 204.5828\n",
            "Epoch 77/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2008840.7500 - mae: 268.0278 - val_loss: 629215.5625 - val_mae: 212.0409\n",
            "Epoch 78/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2008388.5000 - mae: 263.4255 - val_loss: 615035.6250 - val_mae: 177.3980\n",
            "Epoch 79/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1999335.8750 - mae: 262.8591 - val_loss: 613291.3125 - val_mae: 172.6522\n",
            "Epoch 80/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2019167.3750 - mae: 263.6983 - val_loss: 622599.3125 - val_mae: 188.0962\n",
            "Epoch 81/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2011466.3750 - mae: 263.6479 - val_loss: 602665.6875 - val_mae: 174.3170\n",
            "Epoch 82/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 2000246.7500 - mae: 263.8745 - val_loss: 605025.3750 - val_mae: 161.5740\n",
            "Epoch 83/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 2007351.7500 - mae: 268.1765 - val_loss: 601122.3750 - val_mae: 169.6749\n",
            "Epoch 84/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1986113.5000 - mae: 266.4064 - val_loss: 611620.4375 - val_mae: 210.1927\n",
            "Epoch 85/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1994111.5000 - mae: 265.9308 - val_loss: 617817.8125 - val_mae: 246.4660\n",
            "Epoch 86/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2016709.0000 - mae: 272.8267 - val_loss: 622837.8750 - val_mae: 197.8735\n",
            "Epoch 87/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1992065.8750 - mae: 270.9404 - val_loss: 620213.5625 - val_mae: 181.1198\n",
            "Epoch 88/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2027603.6250 - mae: 273.7222 - val_loss: 593682.3125 - val_mae: 176.2967\n",
            "Epoch 89/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2003868.5000 - mae: 269.4300 - val_loss: 610915.4375 - val_mae: 185.0377\n",
            "Epoch 90/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2002798.5000 - mae: 270.2726 - val_loss: 606131.9375 - val_mae: 236.8633\n",
            "Epoch 91/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1986024.5000 - mae: 274.7062 - val_loss: 631695.6875 - val_mae: 202.1493\n",
            "Epoch 92/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 2005895.5000 - mae: 275.2519 - val_loss: 613111.5000 - val_mae: 170.0865\n",
            "Epoch 93/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 2033394.0000 - mae: 270.4234 - val_loss: 606676.0625 - val_mae: 199.1580\n",
            "Epoch 94/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2023492.1250 - mae: 276.3736 - val_loss: 615627.1875 - val_mae: 181.4389\n",
            "Epoch 95/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 2015398.1250 - mae: 271.6024 - val_loss: 597275.5625 - val_mae: 181.4010\n",
            "Epoch 96/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 2004933.8750 - mae: 269.5799 - val_loss: 657045.6250 - val_mae: 198.5936\n",
            "Epoch 97/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2015509.7500 - mae: 271.8743 - val_loss: 606313.6875 - val_mae: 194.4914\n",
            "Epoch 98/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2022396.5000 - mae: 272.4199 - val_loss: 594739.0000 - val_mae: 185.6151\n",
            "Epoch 99/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2012109.6250 - mae: 278.0633 - val_loss: 594884.8125 - val_mae: 190.6996\n",
            "Epoch 100/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2008813.0000 - mae: 272.3871 - val_loss: 608819.3750 - val_mae: 205.7705\n",
            "Processing fold #: 1\n",
            "Validation data includes observations 2250 through 4499\n",
            "Training data includes observations 0 through 2249 joined with observations 4500 through the final observation.\n",
            "\n",
            "Epoch 1/100\n",
            "106/106 [==============================] - 4s 10ms/step - loss: 2932210.5000 - mae: 844.4321 - val_loss: 1913856.2500 - val_mae: 865.0648\n",
            "Epoch 2/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2929912.2500 - mae: 843.5382 - val_loss: 1912670.8750 - val_mae: 865.4965\n",
            "Epoch 3/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2926619.2500 - mae: 842.3321 - val_loss: 1909445.5000 - val_mae: 866.0540\n",
            "Epoch 4/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2921572.5000 - mae: 840.7473 - val_loss: 1902885.3750 - val_mae: 864.1729\n",
            "Epoch 5/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 2916031.0000 - mae: 838.8326 - val_loss: 1894880.6250 - val_mae: 860.5234\n",
            "Epoch 6/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 2909859.0000 - mae: 836.5534 - val_loss: 1891427.7500 - val_mae: 860.1617\n",
            "Epoch 7/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2902728.5000 - mae: 833.9341 - val_loss: 1884099.2500 - val_mae: 856.8568\n",
            "Epoch 8/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2895473.7500 - mae: 830.9716 - val_loss: 1869273.3750 - val_mae: 849.1264\n",
            "Epoch 9/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2886473.2500 - mae: 827.6528 - val_loss: 1864116.7500 - val_mae: 848.0956\n",
            "Epoch 10/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2877798.2500 - mae: 824.0287 - val_loss: 1850577.1250 - val_mae: 842.6035\n",
            "Epoch 11/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2869207.0000 - mae: 820.0496 - val_loss: 1852959.2500 - val_mae: 846.1675\n",
            "Epoch 12/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2858601.5000 - mae: 815.6971 - val_loss: 1829679.8750 - val_mae: 833.5566\n",
            "Epoch 13/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2847086.2500 - mae: 811.0007 - val_loss: 1820723.6250 - val_mae: 830.4550\n",
            "Epoch 14/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2835810.7500 - mae: 805.9762 - val_loss: 1813648.2500 - val_mae: 830.0724\n",
            "Epoch 15/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2822722.0000 - mae: 800.5750 - val_loss: 1793915.7500 - val_mae: 819.8077\n",
            "Epoch 16/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2810565.0000 - mae: 794.8849 - val_loss: 1781871.2500 - val_mae: 814.4917\n",
            "Epoch 17/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2797411.2500 - mae: 788.8482 - val_loss: 1765355.7500 - val_mae: 804.9271\n",
            "Epoch 18/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 2781650.2500 - mae: 782.4202 - val_loss: 1762903.3750 - val_mae: 809.0844\n",
            "Epoch 19/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 2769134.7500 - mae: 775.7331 - val_loss: 1728007.0000 - val_mae: 789.3091\n",
            "Epoch 20/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 2751249.7500 - mae: 768.7553 - val_loss: 1710193.0000 - val_mae: 780.7910\n",
            "Epoch 21/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2735949.0000 - mae: 761.3297 - val_loss: 1694038.5000 - val_mae: 772.7661\n",
            "Epoch 22/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2720363.7500 - mae: 753.6217 - val_loss: 1681898.7500 - val_mae: 765.8854\n",
            "Epoch 23/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2701950.0000 - mae: 745.7389 - val_loss: 1674711.1250 - val_mae: 768.6346\n",
            "Epoch 24/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2686031.0000 - mae: 737.1901 - val_loss: 1654358.1250 - val_mae: 754.1074\n",
            "Epoch 25/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2668535.0000 - mae: 728.3214 - val_loss: 1636881.7500 - val_mae: 750.9221\n",
            "Epoch 26/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2649541.0000 - mae: 719.2379 - val_loss: 1615216.6250 - val_mae: 738.6194\n",
            "Epoch 27/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2628264.2500 - mae: 709.8803 - val_loss: 1598212.0000 - val_mae: 731.6707\n",
            "Epoch 28/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2612489.2500 - mae: 700.1782 - val_loss: 1589585.1250 - val_mae: 729.2171\n",
            "Epoch 29/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2591202.7500 - mae: 690.2490 - val_loss: 1544763.8750 - val_mae: 700.2305\n",
            "Epoch 30/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2574976.2500 - mae: 680.3692 - val_loss: 1535245.2500 - val_mae: 693.3633\n",
            "Epoch 31/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2556430.7500 - mae: 669.0441 - val_loss: 1521156.3750 - val_mae: 695.8909\n",
            "Epoch 32/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 2531526.0000 - mae: 658.3446 - val_loss: 1506856.5000 - val_mae: 688.5008\n",
            "Epoch 33/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 2512953.2500 - mae: 647.2771 - val_loss: 1472052.7500 - val_mae: 668.2863\n",
            "Epoch 34/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2494882.5000 - mae: 636.3610 - val_loss: 1439113.5000 - val_mae: 640.2756\n",
            "Epoch 35/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2476009.7500 - mae: 624.6342 - val_loss: 1424862.8750 - val_mae: 635.4830\n",
            "Epoch 36/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2458626.0000 - mae: 611.4809 - val_loss: 1432433.0000 - val_mae: 655.8165\n",
            "Epoch 37/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2431920.7500 - mae: 599.5672 - val_loss: 1382314.8750 - val_mae: 618.2392\n",
            "Epoch 38/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2412449.0000 - mae: 586.9810 - val_loss: 1358540.5000 - val_mae: 599.4514\n",
            "Epoch 39/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2397410.0000 - mae: 574.4257 - val_loss: 1324846.0000 - val_mae: 577.4905\n",
            "Epoch 40/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2375020.5000 - mae: 561.9308 - val_loss: 1298617.2500 - val_mae: 549.0919\n",
            "Epoch 41/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2352583.7500 - mae: 547.8761 - val_loss: 1304127.6250 - val_mae: 572.2844\n",
            "Epoch 42/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2330626.0000 - mae: 534.6390 - val_loss: 1319221.8750 - val_mae: 600.7787\n",
            "Epoch 43/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2314416.5000 - mae: 521.7841 - val_loss: 1242596.2500 - val_mae: 528.6694\n",
            "Epoch 44/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2294587.7500 - mae: 506.9418 - val_loss: 1246345.3750 - val_mae: 506.4055\n",
            "Epoch 45/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 2275770.7500 - mae: 493.3994 - val_loss: 1232085.1250 - val_mae: 516.7701\n",
            "Epoch 46/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 2250018.0000 - mae: 479.8127 - val_loss: 1219994.5000 - val_mae: 516.4606\n",
            "Epoch 47/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 2233611.5000 - mae: 464.0806 - val_loss: 1178242.2500 - val_mae: 465.0516\n",
            "Epoch 48/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2217131.2500 - mae: 450.0042 - val_loss: 1146893.2500 - val_mae: 458.7086\n",
            "Epoch 49/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2195840.7500 - mae: 436.9404 - val_loss: 1157854.3750 - val_mae: 482.2796\n",
            "Epoch 50/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2184490.2500 - mae: 424.8697 - val_loss: 1099849.1250 - val_mae: 419.9803\n",
            "Epoch 51/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2172032.7500 - mae: 409.9670 - val_loss: 1111090.2500 - val_mae: 414.3326\n",
            "Epoch 52/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2150095.2500 - mae: 396.4400 - val_loss: 1085581.6250 - val_mae: 418.1179\n",
            "Epoch 53/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2142309.0000 - mae: 385.8990 - val_loss: 1069755.7500 - val_mae: 399.2805\n",
            "Epoch 54/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2123204.7500 - mae: 372.0384 - val_loss: 1040743.5625 - val_mae: 363.1874\n",
            "Epoch 55/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2102562.0000 - mae: 357.8942 - val_loss: 1032875.4375 - val_mae: 346.1728\n",
            "Epoch 56/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2100103.7500 - mae: 345.1884 - val_loss: 988338.3125 - val_mae: 321.4135\n",
            "Epoch 57/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2077556.6250 - mae: 334.6436 - val_loss: 982711.4375 - val_mae: 287.8801\n",
            "Epoch 58/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2060908.6250 - mae: 324.5400 - val_loss: 978484.1250 - val_mae: 296.7812\n",
            "Epoch 59/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 2061587.5000 - mae: 316.6717 - val_loss: 975174.4375 - val_mae: 296.8064\n",
            "Epoch 60/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 2051805.6250 - mae: 305.2837 - val_loss: 939887.7500 - val_mae: 274.0043\n",
            "Epoch 61/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 2020387.3750 - mae: 295.8236 - val_loss: 968635.8750 - val_mae: 289.7676\n",
            "Epoch 62/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2009198.0000 - mae: 288.4186 - val_loss: 939969.3750 - val_mae: 252.5995\n",
            "Epoch 63/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2016244.8750 - mae: 285.3545 - val_loss: 930144.1250 - val_mae: 288.4527\n",
            "Epoch 64/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2008943.8750 - mae: 282.6396 - val_loss: 911446.1250 - val_mae: 239.0065\n",
            "Epoch 65/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1999606.1250 - mae: 273.5032 - val_loss: 914698.5000 - val_mae: 257.6130\n",
            "Epoch 66/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1998749.5000 - mae: 275.8238 - val_loss: 901895.1875 - val_mae: 241.3030\n",
            "Epoch 67/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 1986840.3750 - mae: 272.1371 - val_loss: 875230.6875 - val_mae: 219.2865\n",
            "Epoch 68/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 1980868.8750 - mae: 271.1086 - val_loss: 867030.7500 - val_mae: 222.4340\n",
            "Epoch 69/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1984108.7500 - mae: 270.3868 - val_loss: 850132.9375 - val_mae: 198.1925\n",
            "Epoch 70/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1976439.2500 - mae: 265.9090 - val_loss: 893916.8125 - val_mae: 214.3387\n",
            "Epoch 71/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1973327.7500 - mae: 274.4138 - val_loss: 888733.6250 - val_mae: 220.9594\n",
            "Epoch 72/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 1963672.6250 - mae: 272.2767 - val_loss: 853573.8125 - val_mae: 226.0784\n",
            "Epoch 73/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 1967001.6250 - mae: 274.8993 - val_loss: 840520.5000 - val_mae: 192.3380\n",
            "Epoch 74/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1970367.1250 - mae: 271.7693 - val_loss: 864212.0000 - val_mae: 206.8315\n",
            "Epoch 75/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1963664.1250 - mae: 273.4055 - val_loss: 877852.0625 - val_mae: 234.8663\n",
            "Epoch 76/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1957590.6250 - mae: 278.8880 - val_loss: 865075.9375 - val_mae: 214.6704\n",
            "Epoch 77/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1968922.0000 - mae: 282.0302 - val_loss: 838227.0625 - val_mae: 216.5986\n",
            "Epoch 78/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1959496.5000 - mae: 280.7206 - val_loss: 830097.7500 - val_mae: 222.4188\n",
            "Epoch 79/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1957432.6250 - mae: 278.9373 - val_loss: 818953.8750 - val_mae: 208.2871\n",
            "Epoch 80/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1967388.7500 - mae: 284.0439 - val_loss: 807447.1250 - val_mae: 209.1022\n",
            "Epoch 81/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1951615.0000 - mae: 276.4591 - val_loss: 828095.5625 - val_mae: 223.5165\n",
            "Epoch 82/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1969940.8750 - mae: 276.4930 - val_loss: 821830.0000 - val_mae: 203.7254\n",
            "Epoch 83/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1966435.1250 - mae: 283.1546 - val_loss: 819868.3750 - val_mae: 200.4861\n",
            "Epoch 84/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1969848.3750 - mae: 283.7754 - val_loss: 830881.8750 - val_mae: 180.5710\n",
            "Epoch 85/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1967207.1250 - mae: 280.2865 - val_loss: 837028.5625 - val_mae: 206.7661\n",
            "Epoch 86/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 1965132.8750 - mae: 277.2518 - val_loss: 840913.4375 - val_mae: 201.8810\n",
            "Epoch 87/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 1966435.2500 - mae: 280.0772 - val_loss: 873283.4375 - val_mae: 258.9500\n",
            "Epoch 88/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1966129.5000 - mae: 288.8977 - val_loss: 820005.3125 - val_mae: 247.2402\n",
            "Epoch 89/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1974313.8750 - mae: 282.3722 - val_loss: 826203.1875 - val_mae: 199.6635\n",
            "Epoch 90/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1949356.7500 - mae: 281.2287 - val_loss: 862874.1875 - val_mae: 213.1155\n",
            "Epoch 91/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1965570.0000 - mae: 281.0867 - val_loss: 855553.9375 - val_mae: 219.0204\n",
            "Epoch 92/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1960424.7500 - mae: 283.8507 - val_loss: 828435.2500 - val_mae: 217.0552\n",
            "Epoch 93/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1965816.1250 - mae: 285.5789 - val_loss: 851540.0625 - val_mae: 224.9026\n",
            "Epoch 94/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1947254.3750 - mae: 283.6980 - val_loss: 744780.2500 - val_mae: 177.8682\n",
            "Epoch 95/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1962234.6250 - mae: 284.4361 - val_loss: 807738.7500 - val_mae: 215.2349\n",
            "Epoch 96/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1961106.3750 - mae: 283.9116 - val_loss: 812570.5000 - val_mae: 195.3424\n",
            "Epoch 97/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1958246.5000 - mae: 283.3211 - val_loss: 796186.3125 - val_mae: 165.0031\n",
            "Epoch 98/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1958320.0000 - mae: 281.1469 - val_loss: 828697.2500 - val_mae: 183.1939\n",
            "Epoch 99/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 1962982.3750 - mae: 286.2480 - val_loss: 816702.4375 - val_mae: 184.1099\n",
            "Epoch 100/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 1950887.3750 - mae: 286.5461 - val_loss: 822092.8750 - val_mae: 199.2596\n",
            "Processing fold #: 2\n",
            "Validation data includes observations 4500 through 6749\n",
            "Training data includes observations 0 through 4499 joined with observations 6750 through the final observation.\n",
            "\n",
            "Epoch 1/100\n",
            "106/106 [==============================] - 4s 10ms/step - loss: 2809826.7500 - mae: 850.9791 - val_loss: 2281903.5000 - val_mae: 845.5669\n",
            "Epoch 2/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2807242.7500 - mae: 850.1586 - val_loss: 2274860.7500 - val_mae: 843.8442\n",
            "Epoch 3/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2803205.5000 - mae: 848.9775 - val_loss: 2272646.2500 - val_mae: 844.5438\n",
            "Epoch 4/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2798320.7500 - mae: 847.4351 - val_loss: 2265129.0000 - val_mae: 841.8229\n",
            "Epoch 5/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2792621.5000 - mae: 845.5582 - val_loss: 2263337.0000 - val_mae: 841.4559\n",
            "Epoch 6/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2785596.2500 - mae: 843.3055 - val_loss: 2255957.0000 - val_mae: 838.4026\n",
            "Epoch 7/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 2778949.5000 - mae: 840.7283 - val_loss: 2248013.7500 - val_mae: 836.1780\n",
            "Epoch 8/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 2770322.0000 - mae: 837.8046 - val_loss: 2243423.0000 - val_mae: 834.3436\n",
            "Epoch 9/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2762899.2500 - mae: 834.5490 - val_loss: 2227404.2500 - val_mae: 827.4586\n",
            "Epoch 10/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2753173.7500 - mae: 830.9261 - val_loss: 2228635.5000 - val_mae: 828.5655\n",
            "Epoch 11/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2743106.0000 - mae: 827.0259 - val_loss: 2213643.0000 - val_mae: 823.0682\n",
            "Epoch 12/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2732471.2500 - mae: 822.7429 - val_loss: 2198718.0000 - val_mae: 817.3023\n",
            "Epoch 13/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2721004.7500 - mae: 818.1253 - val_loss: 2190895.0000 - val_mae: 814.4279\n",
            "Epoch 14/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2708010.0000 - mae: 813.1162 - val_loss: 2175673.2500 - val_mae: 807.6205\n",
            "Epoch 15/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2695390.0000 - mae: 807.8527 - val_loss: 2158549.5000 - val_mae: 800.5507\n",
            "Epoch 16/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2680945.5000 - mae: 802.1667 - val_loss: 2150841.5000 - val_mae: 798.6114\n",
            "Epoch 17/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2666739.0000 - mae: 796.2040 - val_loss: 2120699.7500 - val_mae: 781.2852\n",
            "Epoch 18/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2654476.0000 - mae: 790.1478 - val_loss: 2106103.7500 - val_mae: 778.4137\n",
            "Epoch 19/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2634204.2500 - mae: 783.2513 - val_loss: 2117635.7500 - val_mae: 785.1717\n",
            "Epoch 20/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 2621460.2500 - mae: 776.3947 - val_loss: 2060668.8750 - val_mae: 754.9905\n",
            "Epoch 21/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 2602605.7500 - mae: 769.0537 - val_loss: 2072404.2500 - val_mae: 765.9471\n",
            "Epoch 22/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 2587761.7500 - mae: 761.3200 - val_loss: 2062532.1250 - val_mae: 762.0869\n",
            "Epoch 23/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2568734.5000 - mae: 753.4074 - val_loss: 2024538.1250 - val_mae: 745.0323\n",
            "Epoch 24/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2549617.5000 - mae: 745.3245 - val_loss: 1991556.3750 - val_mae: 726.3085\n",
            "Epoch 25/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2533723.5000 - mae: 736.2125 - val_loss: 1969369.3750 - val_mae: 715.6042\n",
            "Epoch 26/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2514077.2500 - mae: 727.7187 - val_loss: 1972434.5000 - val_mae: 719.7859\n",
            "Epoch 27/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2494844.7500 - mae: 718.2177 - val_loss: 1915555.3750 - val_mae: 686.8845\n",
            "Epoch 28/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2473607.5000 - mae: 709.0679 - val_loss: 1917975.0000 - val_mae: 694.8420\n",
            "Epoch 29/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2455273.2500 - mae: 698.6711 - val_loss: 1942842.7500 - val_mae: 708.7526\n",
            "Epoch 30/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2437165.0000 - mae: 689.2559 - val_loss: 1883252.8750 - val_mae: 674.6656\n",
            "Epoch 31/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2414795.5000 - mae: 678.2605 - val_loss: 1879991.7500 - val_mae: 675.2492\n",
            "Epoch 32/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2387021.0000 - mae: 666.6942 - val_loss: 1833310.2500 - val_mae: 646.5398\n",
            "Epoch 33/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 2374845.7500 - mae: 655.7997 - val_loss: 1824636.2500 - val_mae: 646.5207\n",
            "Epoch 34/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 2349667.0000 - mae: 644.8259 - val_loss: 1803902.5000 - val_mae: 637.0643\n",
            "Epoch 35/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 2331951.7500 - mae: 632.5527 - val_loss: 1779972.3750 - val_mae: 621.3035\n",
            "Epoch 36/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2309795.7500 - mae: 620.5735 - val_loss: 1779263.1250 - val_mae: 626.0818\n",
            "Epoch 37/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2291788.0000 - mae: 609.4945 - val_loss: 1748518.1250 - val_mae: 607.1085\n",
            "Epoch 38/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2261949.5000 - mae: 596.5568 - val_loss: 1726865.1250 - val_mae: 589.8157\n",
            "Epoch 39/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2252631.2500 - mae: 583.0854 - val_loss: 1731485.3750 - val_mae: 603.2808\n",
            "Epoch 40/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2223472.7500 - mae: 570.9474 - val_loss: 1641602.3750 - val_mae: 535.2390\n",
            "Epoch 41/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2198500.0000 - mae: 555.6613 - val_loss: 1632164.1250 - val_mae: 522.9727\n",
            "Epoch 42/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2173123.2500 - mae: 542.9219 - val_loss: 1635530.6250 - val_mae: 532.1675\n",
            "Epoch 43/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2161750.5000 - mae: 529.6163 - val_loss: 1619526.0000 - val_mae: 526.4164\n",
            "Epoch 44/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2134198.7500 - mae: 515.1656 - val_loss: 1591357.8750 - val_mae: 507.5952\n",
            "Epoch 45/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2120227.5000 - mae: 500.6125 - val_loss: 1577897.8750 - val_mae: 492.3227\n",
            "Epoch 46/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2094124.8750 - mae: 487.4973 - val_loss: 1561998.7500 - val_mae: 481.7442\n",
            "Epoch 47/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 2076285.0000 - mae: 472.6851 - val_loss: 1546852.2500 - val_mae: 475.3962\n",
            "Epoch 48/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 2061908.3750 - mae: 462.4123 - val_loss: 1486247.0000 - val_mae: 435.0088\n",
            "Epoch 49/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 2036384.6250 - mae: 447.8926 - val_loss: 1484129.0000 - val_mae: 427.3038\n",
            "Epoch 50/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2017739.2500 - mae: 429.4877 - val_loss: 1471297.5000 - val_mae: 424.0958\n",
            "Epoch 51/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 2005178.7500 - mae: 416.5721 - val_loss: 1407953.0000 - val_mae: 360.8200\n",
            "Epoch 52/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1994461.0000 - mae: 401.4881 - val_loss: 1414394.3750 - val_mae: 376.5502\n",
            "Epoch 53/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1966413.5000 - mae: 389.0252 - val_loss: 1409754.5000 - val_mae: 360.9490\n",
            "Epoch 54/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1953833.7500 - mae: 375.3577 - val_loss: 1388714.7500 - val_mae: 347.1719\n",
            "Epoch 55/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1939210.8750 - mae: 362.4107 - val_loss: 1380969.1250 - val_mae: 342.9810\n",
            "Epoch 56/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1921381.1250 - mae: 353.6696 - val_loss: 1379440.2500 - val_mae: 343.9451\n",
            "Epoch 57/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1909977.8750 - mae: 337.7953 - val_loss: 1342287.0000 - val_mae: 317.2701\n",
            "Epoch 58/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1895884.7500 - mae: 331.0488 - val_loss: 1337439.6250 - val_mae: 303.1243\n",
            "Epoch 59/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1901195.7500 - mae: 314.8351 - val_loss: 1359537.1250 - val_mae: 333.3085\n",
            "Epoch 60/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 1857623.2500 - mae: 302.8394 - val_loss: 1343895.1250 - val_mae: 318.7606\n",
            "Epoch 61/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 1856664.8750 - mae: 297.3387 - val_loss: 1284818.6250 - val_mae: 254.1894\n",
            "Epoch 62/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 1861153.6250 - mae: 290.3704 - val_loss: 1287633.5000 - val_mae: 234.3046\n",
            "Epoch 63/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1852278.5000 - mae: 285.5540 - val_loss: 1253175.8750 - val_mae: 205.8928\n",
            "Epoch 64/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1829814.3750 - mae: 272.8001 - val_loss: 1283502.3750 - val_mae: 262.6534\n",
            "Epoch 65/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1852005.0000 - mae: 276.7657 - val_loss: 1239949.2500 - val_mae: 197.8077\n",
            "Epoch 66/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1822961.3750 - mae: 271.9925 - val_loss: 1236670.7500 - val_mae: 202.4875\n",
            "Epoch 67/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1803785.5000 - mae: 261.9500 - val_loss: 1228381.0000 - val_mae: 192.2632\n",
            "Epoch 68/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 1838980.8750 - mae: 259.9677 - val_loss: 1259680.0000 - val_mae: 227.6535\n",
            "Epoch 69/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 1801770.5000 - mae: 263.3153 - val_loss: 1235427.0000 - val_mae: 189.6304\n",
            "Epoch 70/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 1834415.2500 - mae: 256.8207 - val_loss: 1220323.8750 - val_mae: 170.1259\n",
            "Epoch 71/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1800077.1250 - mae: 255.9102 - val_loss: 1242016.2500 - val_mae: 194.1061\n",
            "Epoch 72/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1792132.2500 - mae: 252.2172 - val_loss: 1232490.6250 - val_mae: 202.8718\n",
            "Epoch 73/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 1798722.0000 - mae: 255.7269 - val_loss: 1224994.0000 - val_mae: 182.9504\n",
            "Epoch 74/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 1804244.0000 - mae: 259.6515 - val_loss: 1223010.3750 - val_mae: 166.7995\n",
            "Epoch 75/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1810394.1250 - mae: 255.6760 - val_loss: 1228295.2500 - val_mae: 205.3967\n",
            "Epoch 76/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1807353.6250 - mae: 258.7239 - val_loss: 1221081.5000 - val_mae: 194.5141\n",
            "Epoch 77/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1816459.6250 - mae: 257.7713 - val_loss: 1236892.3750 - val_mae: 203.6519\n",
            "Epoch 78/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1804736.6250 - mae: 264.8693 - val_loss: 1215781.5000 - val_mae: 171.3889\n",
            "Epoch 79/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1793159.3750 - mae: 260.3445 - val_loss: 1213706.5000 - val_mae: 172.8062\n",
            "Epoch 80/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1790084.8750 - mae: 256.7889 - val_loss: 1215806.7500 - val_mae: 208.0236\n",
            "Epoch 81/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1802725.7500 - mae: 264.3328 - val_loss: 1216844.6250 - val_mae: 171.9942\n",
            "Epoch 82/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1800293.6250 - mae: 263.2261 - val_loss: 1236222.1250 - val_mae: 191.0910\n",
            "Epoch 83/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1794482.3750 - mae: 269.0564 - val_loss: 1218834.0000 - val_mae: 222.4568\n",
            "Epoch 84/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1818204.3750 - mae: 263.8228 - val_loss: 1218816.3750 - val_mae: 175.6327\n",
            "Epoch 85/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 1809019.0000 - mae: 264.0775 - val_loss: 1216924.5000 - val_mae: 206.5923\n",
            "Epoch 86/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 1802539.7500 - mae: 266.7591 - val_loss: 1216205.5000 - val_mae: 178.8994\n",
            "Epoch 87/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 1802023.6250 - mae: 263.1429 - val_loss: 1221888.3750 - val_mae: 186.3252\n",
            "Epoch 88/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1783204.2500 - mae: 266.1401 - val_loss: 1218424.1250 - val_mae: 192.8027\n",
            "Epoch 89/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1808744.0000 - mae: 266.9268 - val_loss: 1237730.8750 - val_mae: 199.9878\n",
            "Epoch 90/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1803387.5000 - mae: 267.7385 - val_loss: 1220023.6250 - val_mae: 186.2780\n",
            "Epoch 91/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1781745.6250 - mae: 266.8466 - val_loss: 1235718.3750 - val_mae: 209.5343\n",
            "Epoch 92/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1801219.1250 - mae: 265.3620 - val_loss: 1231886.0000 - val_mae: 197.5528\n",
            "Epoch 93/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1802541.6250 - mae: 268.2597 - val_loss: 1224091.2500 - val_mae: 206.4307\n",
            "Epoch 94/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1778073.2500 - mae: 267.0827 - val_loss: 1214692.8750 - val_mae: 184.1341\n",
            "Epoch 95/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1798686.0000 - mae: 269.7483 - val_loss: 1214906.7500 - val_mae: 198.6859\n",
            "Epoch 96/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1792040.0000 - mae: 264.8788 - val_loss: 1220343.5000 - val_mae: 199.3103\n",
            "Epoch 97/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1810156.2500 - mae: 267.4351 - val_loss: 1224308.6250 - val_mae: 183.3869\n",
            "Epoch 98/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1788716.3750 - mae: 267.3214 - val_loss: 1230172.3750 - val_mae: 196.3883\n",
            "Epoch 99/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 1797918.7500 - mae: 263.8479 - val_loss: 1231193.0000 - val_mae: 210.1800\n",
            "Epoch 100/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 1781126.1250 - mae: 267.7122 - val_loss: 1232001.2500 - val_mae: 193.6299\n",
            "Processing fold #: 3\n",
            "Validation data includes observations 6750 through 8999\n",
            "Training data includes observations 0 through 6749 joined with observations 9000 through the final observation.\n",
            "\n",
            "Epoch 1/100\n",
            "106/106 [==============================] - 5s 11ms/step - loss: 1938063.6250 - mae: 847.8506 - val_loss: 4898318.0000 - val_mae: 855.1237\n",
            "Epoch 2/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1936394.0000 - mae: 847.1137 - val_loss: 4894746.0000 - val_mae: 854.2145\n",
            "Epoch 3/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1933126.5000 - mae: 846.0185 - val_loss: 4891767.0000 - val_mae: 855.2052\n",
            "Epoch 4/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1928353.0000 - mae: 844.5533 - val_loss: 4887323.5000 - val_mae: 854.7530\n",
            "Epoch 5/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1922981.6250 - mae: 842.7361 - val_loss: 4880555.0000 - val_mae: 851.3868\n",
            "Epoch 6/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1916498.1250 - mae: 840.5634 - val_loss: 4876815.5000 - val_mae: 850.2728\n",
            "Epoch 7/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1909720.8750 - mae: 838.0433 - val_loss: 4872036.5000 - val_mae: 848.2767\n",
            "Epoch 8/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1901984.0000 - mae: 835.1771 - val_loss: 4861516.0000 - val_mae: 843.7279\n",
            "Epoch 9/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1893684.0000 - mae: 831.9565 - val_loss: 4859165.0000 - val_mae: 843.5034\n",
            "Epoch 10/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1884750.1250 - mae: 828.3880 - val_loss: 4837943.5000 - val_mae: 834.1278\n",
            "Epoch 11/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 1874024.3750 - mae: 824.4665 - val_loss: 4832265.5000 - val_mae: 832.3718\n",
            "Epoch 12/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 1862236.8750 - mae: 820.2077 - val_loss: 4820079.5000 - val_mae: 827.6342\n",
            "Epoch 13/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1852082.7500 - mae: 815.6192 - val_loss: 4810455.0000 - val_mae: 823.7386\n",
            "Epoch 14/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1840505.8750 - mae: 810.6891 - val_loss: 4799601.0000 - val_mae: 819.3799\n",
            "Epoch 15/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1827152.0000 - mae: 805.3926 - val_loss: 4781392.0000 - val_mae: 811.4720\n",
            "Epoch 16/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1814436.6250 - mae: 799.7167 - val_loss: 4778326.0000 - val_mae: 811.1510\n",
            "Epoch 17/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1798606.0000 - mae: 793.7250 - val_loss: 4759423.0000 - val_mae: 801.8066\n",
            "Epoch 18/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1786485.6250 - mae: 787.3878 - val_loss: 4746009.0000 - val_mae: 797.8539\n",
            "Epoch 19/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1769775.0000 - mae: 780.8089 - val_loss: 4719541.0000 - val_mae: 784.3059\n",
            "Epoch 20/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1755403.7500 - mae: 773.9066 - val_loss: 4703271.5000 - val_mae: 777.4044\n",
            "Epoch 21/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1738055.5000 - mae: 766.5323 - val_loss: 4684241.5000 - val_mae: 767.3220\n",
            "Epoch 22/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1718672.6250 - mae: 758.9780 - val_loss: 4686707.0000 - val_mae: 771.5931\n",
            "Epoch 23/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1701910.7500 - mae: 750.7206 - val_loss: 4663344.5000 - val_mae: 759.3656\n",
            "Epoch 24/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 1683901.5000 - mae: 742.4559 - val_loss: 4631705.0000 - val_mae: 745.1179\n",
            "Epoch 25/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 1666255.5000 - mae: 734.1053 - val_loss: 4654549.0000 - val_mae: 757.2395\n",
            "Epoch 26/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1648472.8750 - mae: 725.3099 - val_loss: 4594477.5000 - val_mae: 726.5987\n",
            "Epoch 27/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1623233.8750 - mae: 715.8856 - val_loss: 4599286.5000 - val_mae: 729.9551\n",
            "Epoch 28/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1605775.8750 - mae: 705.6733 - val_loss: 4563284.5000 - val_mae: 717.4077\n",
            "Epoch 29/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1591432.1250 - mae: 696.3325 - val_loss: 4570145.0000 - val_mae: 717.8164\n",
            "Epoch 30/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1566816.3750 - mae: 686.2345 - val_loss: 4560612.5000 - val_mae: 713.7337\n",
            "Epoch 31/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1550758.0000 - mae: 675.5934 - val_loss: 4479100.0000 - val_mae: 660.5594\n",
            "Epoch 32/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1527992.8750 - mae: 664.2659 - val_loss: 4518689.5000 - val_mae: 692.1432\n",
            "Epoch 33/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1499733.3750 - mae: 653.6641 - val_loss: 4440677.5000 - val_mae: 643.0384\n",
            "Epoch 34/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1488206.0000 - mae: 640.5547 - val_loss: 4407210.5000 - val_mae: 620.7426\n",
            "Epoch 35/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1459744.5000 - mae: 629.4917 - val_loss: 4432826.5000 - val_mae: 650.4157\n",
            "Epoch 36/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1443058.7500 - mae: 617.5341 - val_loss: 4402104.0000 - val_mae: 628.6731\n",
            "Epoch 37/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 1420765.3750 - mae: 605.4166 - val_loss: 4367956.0000 - val_mae: 598.6653\n",
            "Epoch 38/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 1404599.5000 - mae: 592.6628 - val_loss: 4358439.5000 - val_mae: 607.0154\n",
            "Epoch 39/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 1381877.6250 - mae: 578.8405 - val_loss: 4336062.0000 - val_mae: 593.4556\n",
            "Epoch 40/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1356988.0000 - mae: 567.7929 - val_loss: 4288551.0000 - val_mae: 557.2095\n",
            "Epoch 41/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1334036.3750 - mae: 554.6100 - val_loss: 4291551.0000 - val_mae: 562.6254\n",
            "Epoch 42/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1306082.1250 - mae: 539.2079 - val_loss: 4250407.0000 - val_mae: 534.2111\n",
            "Epoch 43/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1293419.2500 - mae: 525.7502 - val_loss: 4256554.0000 - val_mae: 538.2542\n",
            "Epoch 44/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1256576.6250 - mae: 511.3057 - val_loss: 4248687.5000 - val_mae: 533.5752\n",
            "Epoch 45/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1248675.7500 - mae: 497.7732 - val_loss: 4206488.0000 - val_mae: 499.9533\n",
            "Epoch 46/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1226417.0000 - mae: 486.0312 - val_loss: 4179827.2500 - val_mae: 482.6202\n",
            "Epoch 47/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1207553.8750 - mae: 468.0279 - val_loss: 4196141.5000 - val_mae: 506.4575\n",
            "Epoch 48/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1193441.1250 - mae: 456.4282 - val_loss: 4183666.7500 - val_mae: 494.9009\n",
            "Epoch 49/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1164108.6250 - mae: 443.5713 - val_loss: 4129392.7500 - val_mae: 446.4917\n",
            "Epoch 50/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 1159656.1250 - mae: 424.8347 - val_loss: 4084414.2500 - val_mae: 405.8799\n",
            "Epoch 51/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 1149748.6250 - mae: 414.1356 - val_loss: 4100216.5000 - val_mae: 422.9867\n",
            "Epoch 52/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1103228.5000 - mae: 399.0465 - val_loss: 4101551.0000 - val_mae: 414.2665\n",
            "Epoch 53/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1107157.8750 - mae: 386.0907 - val_loss: 4061469.2500 - val_mae: 389.7118\n",
            "Epoch 54/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1080239.7500 - mae: 371.5230 - val_loss: 4036406.5000 - val_mae: 345.6405\n",
            "Epoch 55/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1071857.0000 - mae: 358.5120 - val_loss: 4046376.5000 - val_mae: 375.9503\n",
            "Epoch 56/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1052047.0000 - mae: 345.1237 - val_loss: 4003208.2500 - val_mae: 344.5345\n",
            "Epoch 57/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1040421.3750 - mae: 331.6869 - val_loss: 3971080.7500 - val_mae: 290.6644\n",
            "Epoch 58/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 1036535.1250 - mae: 321.4303 - val_loss: 3991772.7500 - val_mae: 317.1828\n",
            "Epoch 59/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 997516.5000 - mae: 309.2715 - val_loss: 3990471.5000 - val_mae: 320.6452\n",
            "Epoch 60/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 996192.0000 - mae: 302.8121 - val_loss: 3970978.7500 - val_mae: 302.9072\n",
            "Epoch 61/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 983524.3125 - mae: 295.5700 - val_loss: 3939157.2500 - val_mae: 280.1820\n",
            "Epoch 62/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 985305.2500 - mae: 286.1700 - val_loss: 3911672.2500 - val_mae: 243.0905\n",
            "Epoch 63/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 972541.0625 - mae: 279.4146 - val_loss: 3900277.2500 - val_mae: 227.8250\n",
            "Epoch 64/100\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 973233.2500 - mae: 271.9766 - val_loss: 3921937.2500 - val_mae: 255.0639\n",
            "Epoch 65/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 959139.7500 - mae: 267.5556 - val_loss: 3902081.2500 - val_mae: 221.3020\n",
            "Epoch 66/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 953998.6250 - mae: 264.2763 - val_loss: 3901001.7500 - val_mae: 223.5883\n",
            "Epoch 67/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 957565.0625 - mae: 266.8576 - val_loss: 3895731.5000 - val_mae: 222.1089\n",
            "Epoch 68/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 949116.2500 - mae: 260.3748 - val_loss: 3889474.7500 - val_mae: 205.6128\n",
            "Epoch 69/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 947688.5000 - mae: 257.6333 - val_loss: 3884895.2500 - val_mae: 199.6147\n",
            "Epoch 70/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 927208.5000 - mae: 259.0483 - val_loss: 3882470.5000 - val_mae: 203.4899\n",
            "Epoch 71/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 952323.8125 - mae: 264.1228 - val_loss: 3866271.7500 - val_mae: 180.5213\n",
            "Epoch 72/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 917249.5625 - mae: 260.9661 - val_loss: 3852654.0000 - val_mae: 201.3238\n",
            "Epoch 73/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 918556.1875 - mae: 256.4398 - val_loss: 3862189.0000 - val_mae: 207.8623\n",
            "Epoch 74/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 939105.7500 - mae: 259.4599 - val_loss: 3870581.7500 - val_mae: 193.5188\n",
            "Epoch 75/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 943872.9375 - mae: 262.7000 - val_loss: 3868402.5000 - val_mae: 195.1617\n",
            "Epoch 76/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 930838.5000 - mae: 265.7783 - val_loss: 3869962.2500 - val_mae: 218.7958\n",
            "Epoch 77/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 931521.9375 - mae: 267.0973 - val_loss: 3902636.5000 - val_mae: 239.9230\n",
            "Epoch 78/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 941807.2500 - mae: 265.8143 - val_loss: 3859073.7500 - val_mae: 182.8779\n",
            "Epoch 79/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 909890.0625 - mae: 263.4395 - val_loss: 3853568.2500 - val_mae: 225.9099\n",
            "Epoch 80/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 908196.0625 - mae: 261.9122 - val_loss: 3856565.5000 - val_mae: 215.4569\n",
            "Epoch 81/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 910558.3750 - mae: 262.7903 - val_loss: 3868999.7500 - val_mae: 215.9746\n",
            "Epoch 82/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 927209.3750 - mae: 268.1316 - val_loss: 3873703.2500 - val_mae: 188.1723\n",
            "Epoch 83/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 917359.2500 - mae: 267.5978 - val_loss: 3878965.7500 - val_mae: 207.4639\n",
            "Epoch 84/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 903763.5625 - mae: 265.9230 - val_loss: 3851110.2500 - val_mae: 211.3187\n",
            "Epoch 85/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 931840.8125 - mae: 270.4287 - val_loss: 3858291.0000 - val_mae: 199.3709\n",
            "Epoch 86/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 923965.0000 - mae: 268.9949 - val_loss: 3870716.2500 - val_mae: 230.2064\n",
            "Epoch 87/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 925722.8750 - mae: 267.8863 - val_loss: 3855913.7500 - val_mae: 192.9608\n",
            "Epoch 88/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 926935.6250 - mae: 268.9929 - val_loss: 3875514.5000 - val_mae: 206.3135\n",
            "Epoch 89/100\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 903821.6250 - mae: 268.0975 - val_loss: 3864385.2500 - val_mae: 223.3735\n",
            "Epoch 90/100\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 913412.5000 - mae: 267.7611 - val_loss: 3848746.7500 - val_mae: 201.2744\n",
            "Epoch 91/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 944408.5625 - mae: 269.6602 - val_loss: 3860108.2500 - val_mae: 160.9865\n",
            "Epoch 92/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 928057.5000 - mae: 265.3420 - val_loss: 3878702.7500 - val_mae: 225.1282\n",
            "Epoch 93/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 916526.2500 - mae: 273.0688 - val_loss: 3865146.2500 - val_mae: 225.8584\n",
            "Epoch 94/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 922447.1875 - mae: 265.8393 - val_loss: 3843532.5000 - val_mae: 206.2114\n",
            "Epoch 95/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 923908.5000 - mae: 267.5538 - val_loss: 3869064.2500 - val_mae: 205.1348\n",
            "Epoch 96/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 932093.5000 - mae: 269.7824 - val_loss: 3856834.0000 - val_mae: 168.9034\n",
            "Epoch 97/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 911797.5625 - mae: 268.7385 - val_loss: 3861298.2500 - val_mae: 190.5477\n",
            "Epoch 98/100\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 935494.2500 - mae: 267.7346 - val_loss: 3850402.5000 - val_mae: 187.5910\n",
            "Epoch 99/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 902150.7500 - mae: 267.0031 - val_loss: 3859335.7500 - val_mae: 198.7667\n",
            "Epoch 100/100\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 914915.6875 - mae: 267.4211 - val_loss: 3873950.5000 - val_mae: 208.8720\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "average_loss_history = [np.mean([x[i] for x in all_train_histories]) for i in range(num_epochs)]\n",
        "average_val_loss_history = [np.mean([x[i] for x in all_val_mae_histories]) for i in range(num_epochs)]\n",
        "print(average_loss_history[-1])\n",
        "#plot training MAE and validation MAE\n",
        "plt.plot(average_loss_history,c='r')\n",
        "plt.plot(average_val_loss_history,c='b')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend(['Training MAE','Validation MAE'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "PfQbBKFxu0Gg",
        "outputId": "1d4826b7-ce80-441b-8c70-879db260f075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "273.5166015625\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "799Ss4r4cDB5"
      },
      "source": [
        "#**Final Configuration and Model Selection:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRoOdimw_TEr",
        "outputId": "a6cbf2f1-2f77-4e6f-9f95-ce0bd2ea1069"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikeras\n",
            "  Downloading scikeras-0.10.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.9/dist-packages (from scikeras) (23.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from scikeras) (1.2.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.10.1)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.10.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "try:\n",
        "    from scikeras.wrappers import KerasRegressor                     \n",
        "except ImportError:\n",
        "    !pip install scikeras\n",
        "    from scikeras.wrappers import KerasRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkVkAJaGcFCJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42ca41b7-78fe-43ca-e1f9-e7ab5840c9c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/65\n",
            "141/141 [==============================] - 4s 7ms/step - loss: 2677467.2500 - mae: 849.4832\n",
            "Epoch 2/65\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 2673445.7500 - mae: 848.3104\n",
            "Epoch 3/65\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 2668185.7500 - mae: 846.5253\n",
            "Epoch 4/65\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 2661146.5000 - mae: 844.1153\n",
            "Epoch 5/65\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 2652498.5000 - mae: 841.1038\n",
            "Epoch 6/65\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 2642012.7500 - mae: 837.4554\n",
            "Epoch 7/65\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 2630958.7500 - mae: 833.2000\n",
            "Epoch 8/65\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 2618226.0000 - mae: 828.3313\n",
            "Epoch 9/65\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 2604418.0000 - mae: 822.8646\n",
            "Epoch 10/65\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 2588163.7500 - mae: 816.7698\n",
            "Epoch 11/65\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 2571839.7500 - mae: 810.0779\n",
            "Epoch 12/65\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 2554978.0000 - mae: 802.8333\n",
            "Epoch 13/65\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 2536628.5000 - mae: 794.9001\n",
            "Epoch 14/65\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 2516917.5000 - mae: 786.4813\n",
            "Epoch 15/65\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 2495671.5000 - mae: 777.4440\n",
            "Epoch 16/65\n",
            "141/141 [==============================] - 1s 10ms/step - loss: 2472343.5000 - mae: 767.7162\n",
            "Epoch 17/65\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 2451837.2500 - mae: 757.7083\n",
            "Epoch 18/65\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 2426621.5000 - mae: 746.6431\n",
            "Epoch 19/65\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 2403032.5000 - mae: 735.5621\n",
            "Epoch 20/65\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 2374100.7500 - mae: 723.1042\n",
            "Epoch 21/65\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 2352598.7500 - mae: 710.6521\n",
            "Epoch 22/65\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 2322034.2500 - mae: 697.5147\n",
            "Epoch 23/65\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 2295118.2500 - mae: 684.4265\n",
            "Epoch 24/65\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 2269250.0000 - mae: 670.0474\n",
            "Epoch 25/65\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 2243076.5000 - mae: 655.1776\n",
            "Epoch 26/65\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 2213323.5000 - mae: 639.7853\n",
            "Epoch 27/65\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 2183291.2500 - mae: 624.4248\n",
            "Epoch 28/65\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 2148268.5000 - mae: 607.9139\n",
            "Epoch 29/65\n",
            "141/141 [==============================] - 1s 10ms/step - loss: 2123338.5000 - mae: 589.7443\n",
            "Epoch 30/65\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 2097299.0000 - mae: 573.2260\n",
            "Epoch 31/65\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 2072630.3750 - mae: 555.3203\n",
            "Epoch 32/65\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 2034845.2500 - mae: 537.7337\n",
            "Epoch 33/65\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 2012258.1250 - mae: 520.4830\n",
            "Epoch 34/65\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 1989655.2500 - mae: 502.8828\n",
            "Epoch 35/65\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 1963998.1250 - mae: 481.9879\n",
            "Epoch 36/65\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1936318.0000 - mae: 464.0812\n",
            "Epoch 37/65\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 1913449.1250 - mae: 444.6307\n",
            "Epoch 38/65\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 1886746.0000 - mae: 426.4397\n",
            "Epoch 39/65\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 1863754.6250 - mae: 407.4724\n",
            "Epoch 40/65\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 1845780.0000 - mae: 387.8099\n",
            "Epoch 41/65\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 1827986.3750 - mae: 373.1053\n",
            "Epoch 42/65\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 1804699.0000 - mae: 352.1781\n",
            "Epoch 43/65\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 1783405.6250 - mae: 338.3743\n",
            "Epoch 44/65\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 1766384.1250 - mae: 321.1213\n",
            "Epoch 45/65\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 1748502.3750 - mae: 308.5842\n",
            "Epoch 46/65\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1726674.2500 - mae: 293.4543\n",
            "Epoch 47/65\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1729027.0000 - mae: 283.6245\n",
            "Epoch 48/65\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1710527.1250 - mae: 277.1783\n",
            "Epoch 49/65\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1703116.2500 - mae: 272.6382\n",
            "Epoch 50/65\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 1683481.3750 - mae: 263.1884\n",
            "Epoch 51/65\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 1693284.1250 - mae: 258.3927\n",
            "Epoch 52/65\n",
            "141/141 [==============================] - 1s 6ms/step - loss: 1695384.7500 - mae: 259.6027\n",
            "Epoch 53/65\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 1676251.0000 - mae: 254.0105\n",
            "Epoch 54/65\n",
            "141/141 [==============================] - 1s 10ms/step - loss: 1689184.0000 - mae: 258.9175\n",
            "Epoch 55/65\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 1670579.3750 - mae: 258.1956\n",
            "Epoch 56/65\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 1683310.7500 - mae: 259.3665\n",
            "Epoch 57/65\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 1674652.1250 - mae: 264.1024\n",
            "Epoch 58/65\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 1691019.8750 - mae: 261.1527\n",
            "Epoch 59/65\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 1669002.5000 - mae: 261.4814\n",
            "Epoch 60/65\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 1678201.6250 - mae: 263.2880\n",
            "Epoch 61/65\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 1676337.0000 - mae: 267.4954\n",
            "Epoch 62/65\n",
            "141/141 [==============================] - 1s 7ms/step - loss: 1658729.6250 - mae: 263.5079\n",
            "Epoch 63/65\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 1655362.0000 - mae: 262.2946\n",
            "Epoch 64/65\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 1664494.8750 - mae: 262.4906\n",
            "Epoch 65/65\n",
            "141/141 [==============================] - 1s 10ms/step - loss: 1659087.7500 - mae: 264.9715\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ffa6c04a3a0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "model = build_model()\n",
        "model.fit(predictors,labels,epochs=65, batch_size=64,verbose = 1) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFDAd_jXiFHR"
      },
      "source": [
        "Here's what the resulting model looks like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmZBB8Y4iJER",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9919100-3b8a-4be9-a50b-93b84007fdf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Bluebikes-Duration-Model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_5 (Dense)             (None, 256)               2560      \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " first_hidden (Dense)        (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " batch_normalization_20 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " second_hidden (Dense)       (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_27 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " batch_normalization_21 (Bat  (None, 64)               256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " third_hidden (Dense)        (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_28 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " batch_normalization_22 (Bat  (None, 32)               128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " fourth_hidden (Dense)       (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_29 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " batch_normalization_23 (Bat  (None, 16)               64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " output (Dense)              (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 47,297\n",
            "Trainable params: 46,817\n",
            "Non-trainable params: 480\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Suggestions on Improvements**"
      ],
      "metadata": {
        "id": "vSAaM7OuAc1j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cross-validation shows that the model may suffer underfitting. This may be due to the algorithm of the training& validation sets. The dropout in layers is not executed on validation dataset,(which will prevent overfitting in training). I would suggest using a smaller dropout rate in this case, shuffling the observations to do cross-validation, increase number of hidden layers to increase depth of neural network,decrease complexity of the model."
      ],
      "metadata": {
        "id": "dsRN4l1bAhR6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xWiloTgSuC_"
      },
      "source": [
        "#**Final Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVpo01AsSySZ"
      },
      "source": [
        "Don't modify this section; this is the code I will use to evaluate that your model is output properly and that it can generate predictions on new test observations it has never seen before. If your model breaks when I feed it the new data, I will deduct marks, so please ensure that your data pre-processing function works properly!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzEJ5p5tS4Zz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "c6959e60-4d00-49c1-b8a2-2b5732b9c782"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5452d0a5-082a-437d-abd0-824a2cd94b3d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5452d0a5-082a-437d-abd0-824a2cd94b3d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving bluebikes_holdout.csv to bluebikes_holdout (1).csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-8b4ede47dd52>:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[\"starttime_inhour\"][i] = int(data[\"starttime\"][i][0:2])*60 + int(data[\"starttime\"][i][3:5]) + float(data[\"starttime\"][i][5:7])\n",
            "<ipython-input-12-8b4ede47dd52>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[\"endtime_inhour\"][i] = int(data[\"stoptime\"][i][0:2])*60 + int(data[\"stoptime\"][i][3:5]) + float(data[\"stoptime\"][i][5:7])\n",
            "<ipython-input-12-8b4ede47dd52>:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[\"distance\"][i] = hs.haversine((data[\"start station latitude\"][i],data[\"start station longitude\"][i]),(data[\"end station latitude\"][i],data[\"end station longitude\"][i]))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64/64 [==============================] - 0s 3ms/step - loss: 30415.4941 - mae: 166.8929\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "# I'm going to upload my holdout dataset (same set of features)\n",
        "uploaded = files.upload()\n",
        "bluebike_holdout = pd.read_csv(io.BytesIO(uploaded['bluebikes_holdout.csv']))\n",
        "\n",
        "# I'm then going to pre-process it using your commands.\n",
        "holdout_predictors, holdout_labels = processData(bluebike_holdout)\n",
        "\n",
        "# Then I'm going to evaluate your model's performance on that data.\n",
        "loss_metrics = model.evaluate(holdout_predictors,holdout_labels,verbose=1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}